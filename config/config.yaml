learning_rate: 0.1
batch_size: 8
layer_sizes: [784, 32, 10]
activations: ["relu", "softmax"]
loss: "CrossEntropy"
epochs: 20
l1_lambda: 0
l2_lambda: 0.1
